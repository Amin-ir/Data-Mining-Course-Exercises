{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_normalize(serie: pd.Series):\n",
    "    return (serie - serie.min()) / (serie.max() - serie.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numerical_attributes(dataset: pd.DataFrame, target_attribute: str):\n",
    "    normalized = dataset\n",
    "    for attribute in [attr for attr in dataset.columns if dataset[attr].dtype.name != 'object' and attr != target_attribute]: # only numerical values\n",
    "        normalized[attribute] = minmax_normalize(dataset[attribute])\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNPoint:\n",
    "    def __init__(self, vector, distance):\n",
    "        self.vector = vector\n",
    "        self.distance = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def fit(self, train_dataset: pd.DataFrame, target_attribute):\n",
    "        normalized_data = normalize_numerical_attributes(train_dataset, target_attribute)\n",
    "        self.data = normalized_data\n",
    "        self.target_attribute = target_attribute\n",
    "    def predict(self, k, test_tuple: pd.Series):\n",
    "        vector_distances = []\n",
    "        \n",
    "        for index, row in self.data.iterrows(): # Setting distance\n",
    "            sum = 0\n",
    "            for column in self.data.columns:\n",
    "                if self.data[column].dtype == 'object': # nominal field\n",
    "                    if row[column] is None or test_tuple[column] is None:\n",
    "                        sum += 1\n",
    "                else: # numerical\n",
    "                    if row[column] is None and test_tuple[column] is None: # both null\n",
    "                        sum += 1\n",
    "                    elif row[column] is not None and test_tuple[column] is not None: # both not-null\n",
    "                        sum += pow(row[column] - test_tuple[column], 2)# euclidean\n",
    "                    else: # one of them is null\n",
    "                        sum += max(1 - row[column], 1 - test_tuple[column])\n",
    "\n",
    "            vector_distances.append(KNNPoint(row, math.sqrt(sum)))\n",
    "\n",
    "        vector_distances = sorted(vector_distances, key=lambda x: x.distance)\n",
    "        nearest_k = vector_distances[:k]\n",
    "\n",
    "        return pd.Series([item.vector[self.target_attribute] for item in nearest_k]).mode()[0] # major voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/student_admission_record_dirty.csv')\n",
    "knn_classifier = KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157 entries, 0 to 156\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Name                    147 non-null    object \n",
      " 1   Age                     147 non-null    float64\n",
      " 2   Gender                  147 non-null    object \n",
      " 3   Admission Test Score    146 non-null    float64\n",
      " 4   High School Percentage  146 non-null    float64\n",
      " 5   City                    147 non-null    object \n",
      " 6   Admission Status        147 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogha\\AppData\\Local\\Temp\\ipykernel_11308\\3663963327.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\mogha\\AppData\\Local\\Temp\\ipykernel_11308\\3663963327.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_set(dataset: pd.DataFrame, number_of_sets: int):\n",
    "    dataset_length = len(dataset)\n",
    "    partition_size = int(dataset_length / number_of_sets)\n",
    "    return [dataset[counter * partition_size:(counter + 1) * partition_size] for counter in range(0, number_of_sets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_k_fold_cross_validation(classifier: KNN, dataset: pd.DataFrame,k: int, candidate_neighbor_numbers: list):\n",
    "    data_partitions = partition_set(dataset, k)\n",
    "    best_neighbor_number, best_accuracy = 0, 0\n",
    "    for neighbor_number in candidate_neighbor_numbers:\n",
    "        for index in range(0, k):\n",
    "            test_dataset = data_partitions[index]\n",
    "            training_dataset = pd.concat([partition for partition in data_partitions if partition is not test_dataset], axis=0)\n",
    "            classifier.fit(training_dataset, 'Admission Status')\n",
    "            tn, tp, fn, fp = 0, 0, 0, 0\n",
    "            for test_index, test_tuple in test_dataset.iterrows():\n",
    "                prediction = classifier.predict(neighbor_number, test_tuple)\n",
    "                if prediction == 'Accepted' and test_tuple['Admission Status'] == 'Accepted':\n",
    "                    tp += 1\n",
    "                elif prediction == 'Rejected' and test_tuple['Admission Status'] == 'Rejected':\n",
    "                    tn += 1\n",
    "                elif prediction == 'Accepted' and test_tuple['Admission Status'] == 'Rejected':\n",
    "                    fp += 1\n",
    "                elif prediction == 'Rejected' and test_tuple['Admission Status'] == 'Accepted':\n",
    "                    fn += 1\n",
    "\n",
    "            accuracy = (tp + tn) / len(test_dataset)\n",
    "            if accuracy >= best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_neighbor_number = neighbor_number\n",
    "\n",
    "    return best_neighbor_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(perform_k_fold_cross_validation(knn_classifier, df, 5, [n for n in range(2, 20)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
